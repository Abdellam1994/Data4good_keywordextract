{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1><center style=\"color:#2B3698\">Merging the different methods for generating matching keywords</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Importing the different libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import gensim\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from stemming.porter2 import stem\n",
    "from itertools import repeat\n",
    "\n",
    "model       = gensim.models.KeyedVectors.load_word2vec_format('/home/theapemachine/data/word2vec/text8-vector.bin', binary=True)\n",
    "nlp         = spacy.load('en')\n",
    "w2v_words   = []\n",
    "wn_words    = []\n",
    "spacy_words = []\n",
    "w2v_stems   = []\n",
    "wn_stems    = []\n",
    "spacy_stems = []\n",
    "words       = []\n",
    "categories  = [\n",
    "    'advice',\n",
    "    'hygiene',\n",
    "    'equipment',\n",
    "    'activities',\n",
    "    'technology',\n",
    "    'info',\n",
    "    'administrative',\n",
    "    'job',\n",
    "    'education',\n",
    "    'home',\n",
    "    'health',\n",
    "    'food'\n",
    "]\n",
    "\n",
    "def most_similar(word):\n",
    "    queries = [w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15]\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return by_similarity[:10]\n",
    "\n",
    "def iterate(origin):\n",
    "    try:\n",
    "        for synset in wn.synsets(origin):\n",
    "            for lemma in synset.lemma_names():\n",
    "                if lemma.find('_') == -1:\n",
    "                    w2v_words.append(lemma)\n",
    "                    w2v_stems.append(stem(lemma))\n",
    "\n",
    "        for word in model.most_similar(origin):\n",
    "            if word[0].find('_') == -1:\n",
    "                wn_words.append(word[0])\n",
    "                wn_stems.append(stem(word[0]))\n",
    "\n",
    "        for w in most_similar(nlp.vocab[u''.join([origin])]):\n",
    "            spacy_words.append(w.lower_)\n",
    "            spacy_stems.append(stem(w.lower_))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def clean(w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words):\n",
    "    for w in w2v_words:\n",
    "        if stem(w) in wn_stems or stem(w) in spacy_stems:\n",
    "            words.append(w)\n",
    "\n",
    "    for w in wn_words:\n",
    "        if stem(w) in w2v_stems or stem(w) in spacy_stems:\n",
    "            words.append(w)\n",
    "\n",
    "    for w in spacy_words:\n",
    "        if stem(w) in w2v_stems or stem(w) in wn_stems:\n",
    "            words.append(w)\n",
    "\n",
    "    return [], [], [], [], [], []\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    iterate(sys.argv[1])\n",
    "\n",
    "    w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "        w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "    )\n",
    "\n",
    "    for i in repeat(None, 2):\n",
    "        for w in np.unique(words):\n",
    "            iterate(w)\n",
    "\n",
    "        w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "            w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "        )\n",
    "\n",
    "    for w in np.unique(words):\n",
    "        print w\n",
    "\n",
    "    words = []\n",
    "else:\n",
    "    for category in categories:\n",
    "        print \"------------------\"\n",
    "        print category\n",
    "        print \"------------------\"\n",
    "        iterate(category)\n",
    "\n",
    "        w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "            w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "        )\n",
    "\n",
    "        for i in repeat(None, 2):\n",
    "            for w in np.unique(words):\n",
    "                iterate(w)\n",
    "\n",
    "            w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "                w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "            )\n",
    "\n",
    "        for w in np.unique(words):\n",
    "            print w\n",
    "\n",
    "        print\n",
    "        words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories  = [\n",
    "    'advice',\n",
    "    'hygiene',\n",
    "    'equipment',\n",
    "    'activities',\n",
    "    'technology',\n",
    "    'info',\n",
    "    'administrative',\n",
    "    'job',\n",
    "    'education',\n",
    "    'home',\n",
    "    'health',\n",
    "    'food'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis : our input will be supposed to be a dictionnary of the form {\"name_category\" : {\"matching_keywords\" : {\"Model\" : score}}} and the return would be {\"name_category\" : {\"matching_keywords\" : score}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question : Deal with stems or all words ?\n",
    "Hypothesis : we will keep only stems in our inputs and then generate the lems afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO : create a function generate_input(models, name_models, category) and return an input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO : generate a function that takes as input a word and returns matching keywords and scores using wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO : generate a function that takes as input a word and returns matching keywords and scores using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TO DO : generate a function that takes as input a word and returns matching keywords and scores using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ftp.cs.toronto.edu/pub/gh/Budanitsky+Hirst-2001.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
