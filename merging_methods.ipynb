{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1><center style=\"color:#2B3698\">Merging the different methods for generating matching keywords</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Importing the different libraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import gensim\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from stemming.porter2 import stem\n",
    "from itertools import repeat\n",
    "\n",
    "model       = gensim.models.KeyedVectors.load_word2vec_format('/home/theapemachine/data/word2vec/text8-vector.bin', binary=True)\n",
    "nlp         = spacy.load('en')\n",
    "w2v_words   = []\n",
    "wn_words    = []\n",
    "spacy_words = []\n",
    "w2v_stems   = []\n",
    "wn_stems    = []\n",
    "spacy_stems = []\n",
    "words       = []\n",
    "categories  = [\n",
    "    'advice',\n",
    "    'hygiene',\n",
    "    'equipment',\n",
    "    'activities',\n",
    "    'technology',\n",
    "    'info',\n",
    "    'administrative',\n",
    "    'job',\n",
    "    'education',\n",
    "    'home',\n",
    "    'health',\n",
    "    'food'\n",
    "]\n",
    "\n",
    "def most_similar(word):\n",
    "    queries = [w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15]\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return by_similarity[:10]\n",
    "\n",
    "def iterate(origin):\n",
    "    try:\n",
    "        for synset in wn.synsets(origin):\n",
    "            for lemma in synset.lemma_names():\n",
    "                if lemma.find('_') == -1:\n",
    "                    w2v_words.append(lemma)\n",
    "                    w2v_stems.append(stem(lemma))\n",
    "\n",
    "        for word in model.most_similar(origin):\n",
    "            if word[0].find('_') == -1:\n",
    "                wn_words.append(word[0])\n",
    "                wn_stems.append(stem(word[0]))\n",
    "\n",
    "        for w in most_similar(nlp.vocab[u''.join([origin])]):\n",
    "            spacy_words.append(w.lower_)\n",
    "            spacy_stems.append(stem(w.lower_))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def clean(w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words):\n",
    "    for w in w2v_words:\n",
    "        if stem(w) in wn_stems or stem(w) in spacy_stems:\n",
    "            words.append(w)\n",
    "\n",
    "    for w in wn_words:\n",
    "        if stem(w) in w2v_stems or stem(w) in spacy_stems:\n",
    "            words.append(w)\n",
    "\n",
    "    for w in spacy_words:\n",
    "        if stem(w) in w2v_stems or stem(w) in wn_stems:\n",
    "            words.append(w)\n",
    "\n",
    "    return [], [], [], [], [], []\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    iterate(sys.argv[1])\n",
    "\n",
    "    w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "        w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "    )\n",
    "\n",
    "    for i in repeat(None, 2):\n",
    "        for w in np.unique(words):\n",
    "            iterate(w)\n",
    "\n",
    "        w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "            w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "        )\n",
    "\n",
    "    for w in np.unique(words):\n",
    "        print w\n",
    "\n",
    "    words = []\n",
    "else:\n",
    "    for category in categories:\n",
    "        print \"------------------\"\n",
    "        print category\n",
    "        print \"------------------\"\n",
    "        iterate(category)\n",
    "\n",
    "        w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "            w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "        )\n",
    "\n",
    "        for i in repeat(None, 2):\n",
    "            for w in np.unique(words):\n",
    "                iterate(w)\n",
    "\n",
    "            w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems = clean(\n",
    "                w2v_words, wn_words, spacy_words, w2v_stems, wn_stems, spacy_stems, words\n",
    "            )\n",
    "\n",
    "        for w in np.unique(words):\n",
    "            print w\n",
    "\n",
    "        print\n",
    "        words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Merging the different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "categories  = [\n",
    "    'advice',\n",
    "    'hygiene',\n",
    "    'equipment',\n",
    "    'activities',\n",
    "    'technology',\n",
    "    'info',\n",
    "    'administrative',\n",
    "    'job',\n",
    "    'education',\n",
    "    'home',\n",
    "    'health',\n",
    "    'food'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hypothesis : our input will be supposed to be a dictionnary of the form {\"name_category\" : {\"matching_keywords\" : {\"Model\" : score}}} and the return would be {\"name_category\" : {\"matching_keywords\" : score}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Question : Deal with stems or all words ?\n",
    "Hypothesis : we will keep only stems in our inputs and then generate the lems afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TO DO : create a function generate_input(models, name_models, category) and return an input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### TO DO : generate a function that takes as input a word and returns matching keywords and scores using wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from stemming.porter2 import stem\n",
    "from nltk.corpus import wordnet_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_wordnet(word, matching_keyword) :\n",
    "    word = wn.synsets(word)[0]\n",
    "    matching_keyword = wn.synsets(matching_keyword)[0]\n",
    "    score = 0\n",
    "    try :\n",
    "        score += word.path_similarity(matching_keyword)\n",
    "        score += word.lch_similarity(matching_keyword)\n",
    "        score += word.wup_similarity(matching_keyword)\n",
    "    except :\n",
    "        pass\n",
    "    # TO DO add an other argument to the function (needs 3 arguments)\n",
    "    # score += word.jcn_similarity(matching_keyword) \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_words_wordnet(word, n = 3) :\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    word: word to compute similarities to (can be a category word)\n",
    "    n: number of similar words to get\n",
    "    \"\"\"\n",
    "    \n",
    "    name_model = \"wordnet\"\n",
    "    result = {}\n",
    "    \n",
    "    for synset in wn.synsets(word):\n",
    "        print(word)\n",
    "        for lemma in synset.lemma_names():\n",
    "            result[stem(lemma)] = {name_model : score_wordnet(word, lemma)}\n",
    "    \n",
    "    \n",
    "    for i in range(n) :\n",
    "        for origin in result.keys():\n",
    "            print(origin)\n",
    "            for synset in wn.synsets(origin):\n",
    "                for lemma in synset.lemma_names():\n",
    "                    result[stem(lemma)] = {name_model : score_wordnet(word, lemma)}\n",
    "        \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food\n",
      "food\n",
      "food\n",
      "food\n",
      "nutrient\n",
      "food_for_thought\n",
      "solid_food\n",
      "intellectual_nourish\n",
      "nourish\n",
      "nutrit\n",
      "aliment\n",
      "food\n",
      "solid_food\n",
      "alimentari\n",
      "nutriti\n",
      "intellectual_nourish\n",
      "nutrient\n",
      "food_for_thought\n",
      "nourish\n",
      "nutrit\n",
      "aliment\n",
      "food\n",
      "susten\n",
      "nutriment\n",
      "solid_food\n",
      "alimentari\n",
      "nutriti\n",
      "victual\n",
      "sustain\n",
      "nurtur\n",
      "intellectual_nourish\n",
      "nutrient\n",
      "food_for_thought\n",
      "nutrifi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'affirm': {'wordnet': 0},\n",
       " u'aliment': {'wordnet': 0},\n",
       " u'alimentari': {'wordnet': 0},\n",
       " u'comest': {'wordnet': 4.353529888257349},\n",
       " u'confirm': {'wordnet': 0},\n",
       " u'corrobor': {'wordnet': 0},\n",
       " u'eatabl': {'wordnet': 4.353529888257349},\n",
       " u'edibl': {'wordnet': 4.353529888257349},\n",
       " u'food': {'wordnet': 5.637586159726386},\n",
       " u'food_for_thought': {'wordnet': 1.6168192485505222},\n",
       " u'get': {'wordnet': 0.9743074561930456},\n",
       " u'have': {'wordnet': 2.2345331535282154},\n",
       " u'hold': {'wordnet': 1.2924170220450686},\n",
       " u'hold_up': {'wordnet': 0},\n",
       " u'intellectual_nourish': {'wordnet': 1.6168192485505222},\n",
       " u'keep': {'wordnet': 1.4972666445037728},\n",
       " u'keep_up': {'wordnet': 0},\n",
       " u'maintain': {'wordnet': 0},\n",
       " u'nourish': {'wordnet': 0},\n",
       " u'nurtur': {'wordnet': 1.6168192485505222},\n",
       " u'nutrient': {'wordnet': 5.637586159726386},\n",
       " u'nutrifi': {'wordnet': 0},\n",
       " u'nutriment': {'wordnet': 4.353529888257349},\n",
       " u'nutrit': {'wordnet': 0},\n",
       " u'nutriti': {'wordnet': 0},\n",
       " u'pabulum': {'wordnet': 4.353529888257349},\n",
       " u'prolong': {'wordnet': 0},\n",
       " u'solid_food': {'wordnet': 2.828148247292286},\n",
       " u'substanti': {'wordnet': 0},\n",
       " u'suffer': {'wordnet': 0},\n",
       " u'support': {'wordnet': 1.4972666445037728},\n",
       " u'sustain': {'wordnet': 0},\n",
       " u'susten': {'wordnet': 4.353529888257349},\n",
       " u'victual': {'wordnet': 4.353529888257349}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_words_wordnet(\"food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### TO DO : generate a function that takes as input a word and returns matching keywords and scores using word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def most_similar_word2vec(word, n, path, model_name = \"text8-vector.bin\"):\n",
    "    \"\"\" Most similar words to word and their scores.\n",
    "    Parameters\n",
    "    ----------\n",
    "    word: word to compute similarities to (can be a category word)\n",
    "    n: number of similar words to get\n",
    "    path: path of the pretrained word2vec model\n",
    "    model_name: name of the pretrained word2vec model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d: {word: {similar_word: {word2vec: word2vec_score}}\n",
    "\n",
    "    barplot: single bar plot\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    # Load Google's pre-trained Word2Vec model\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(os.path.join(path, \"text8-vector.bin\"), binary=True) \n",
    "    d[word] = {key: {\"word2vec\": value} for (key, value) in model.most_similar(\"food\", topn = n)}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### TO DO : generate a function that takes as input a word and returns matching keywords and scores using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "http://ftp.cs.toronto.edu/pub/gh/Budanitsky+Hirst-2001.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import error : https://stackoverflow.com/questions/15526996/ipython-notebook-locale-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "origin = \"food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wn.synsets(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for synset in wn.synsets(origin):\n",
    "    for lemma in synset.lemma_names():\n",
    "        l.append(stem(lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for origin in l :\n",
    "    for synset in wn.synsets(origin):\n",
    "        for lemma in synset.lemma_names():\n",
    "            l.append(stem(lemma))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
